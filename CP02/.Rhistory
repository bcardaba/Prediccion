library(tidyverse)
library(broom) # modelos en df
library(flextable) # Tablas formateadas
library(mgcv) # estimar gam
library(reshape2) # melt
mcycle <- MASS::mcycle
# Examine the mcycle data frame
head(mcycle)
ggplot(data = mcycle, mapping = aes(x = times, y = accel)) +
layer(geom = "point",stat = "identity",position = "identity") +
theme_bw() + theme(legend.key = element_blank())
# Fit a linear model
lm_mod <- lm(accel~times, data = mcycle)
width(flextable(tidy(lm_mod)), width = 1.5)
width(flextable(glance(lm_mod)), width = 1.5)
# Visualize the model
termplot(lm_mod, partial.resid = TRUE, se = TRUE)
baseplot1 <- ggplot(data = mcycle, mapping = aes(x = times, y = accel)) +
layer(geom = "point",stat = "identity",position = "identity") +
theme_bw() + theme(legend.key = element_blank())
baseplot1
knots <- c(15,20,32,40)
mcycle$X1 <- pmax(0, mcycle$times - knots[1])
mcycle$X2 <- pmax(0, mcycle$times - knots[2])
mcycle$X3 <- pmax(0, mcycle$times - knots[3])
mcycle$X4 <- pmax(0, mcycle$times - knots[4])
mcycle
#Linear splines
lsp <- lm(accel ~ times + X1 + X2 + X3 + X4, data = mcycle)
summary(lsp)
newdat <- data.frame(times = seq(0,60,0.01))
newdat$X1 <- pmax(0, newdat$times - knots[1])
newdat$X2 <- pmax(0, newdat$times - knots[2])
newdat$X3 <- pmax(0, newdat$times - knots[3])
newdat$X4 <- pmax(0, newdat$times - knots[4])
newdat$linear <- predict(lsp, newdata = newdat)
#Quadratic splines
qsp <- lm(accel ~ times + I(times^2) + I(X1^2) + I(X2^2) + I(X3^2) + I(X4^2), data = mcycle)
summary(qsp)
newdat$quadratic <- predict(qsp, newdata = newdat)
#Cubic splines
csp <- lm(accel ~ times + I(times^2) + I(times^3) + I(X1^3) + I(X2^3) + I(X3^3) + I(X4^3), data = mcycle)
summary(csp)
newdat$cubic <- predict(csp, newdata = newdat)
#Plot splines
newdatMelt <- melt(data          = newdat,
id.vars       = c("times",paste0("X",1:4)),
variable.name = "spline",
value.name    = "value")
baseplot1 +
layer(geom = "line", data = newdatMelt,stat = "identity", position = "identity",
mapping = aes(x = times, y = value, color = spline)) +
facet_wrap( ~ spline, ncol = 1)
# Fit the model
gam_mod <- gam(accel ~ s(times), data = mcycle)
# Plot the results
plot(gam_mod, residuals = TRUE, pch = 1)
coef(gam_mod)
# Complexity
# Fit a GAM with 3 basis functions
gam_mod_k3 <- gam(accel ~ s(times, k = 3), data = mcycle)
# Fit with 20 basis functions
gam_mod_k20 <- gam(accel ~ s(times, k = 20), data = mcycle)
# Visualize the GAMs
plot(gam_mod_k3, residuals = TRUE, pch = 1)
plot(gam_mod_k20, residuals = TRUE, pch = 1)
# Fix the smoothing parameter at 0.1
gam_mod_s1 <- gam(accel ~ s(times), data = mcycle, sp = 0.01)
# Fix the smoothing parameter at 0.0001
gam_mod_s2 <- gam(accel ~ s(times), data = mcycle, sp = 0.0001)
# Plot both models
plot(gam_mod_s1, residuals = TRUE, pch = 1)
plot(gam_mod_s2, residuals = TRUE, pch = 1)
gam_mod_sk <- gam(accel ~ s(times, k = 50), data = mcycle, sp = 0.0001)
# Visualize the model
plot(gam_mod_sk, residuals = TRUE, pch = 1)
# Checking
gam.check(gam_mod_sk)
gam.check(gam_mod_s1)
gam.check(gam_mod_s2)
gam.check(gam_mod_k3)
gam.check(gam_mod_k20)
library(tidyverse)
library(broom) # modelos en df
library(flextable) # Tablas formateadas
library(mgcv) # estimar gam
library(reshape2) # melt
library(readr)
library(dplyr)
library(skimr)
library(here) # Comentar
library(janitor) # Clean names
library(magrittr) # Pipe operators
library(corrplot) # Correlations
library(ggcorrplot)  # Correlations
library(PerformanceAnalytics) # Correlations
library(leaps) # Model selection
library(glmnet)
library(gam)
library(fBasics)
library(nortest)
library(MASS)
library(imputeTS)
library(gam)
raw_data <- read_csv("pisasci2006.csv")
str(raw_data) # visualizamos el tipo de variables de la base de datos, el número de observaciones y de variables
raw_data %<>% clean_names() # %<>% es un doble pipe, mete row_Data en clean_nnba y el resultado lo guarda en rowdata
# raw_data <- clean_nnba(raw_data)
# raw_data <- raw_data %>% clean_nnba()
# lo que hace es que nos limpia los nombre, todas en minusculas quitar los puntos
colnames(raw_data)
dim(raw_data)
skim(raw_data)
raw_data <- na_mean(raw_data) # sustituimos los NA por la media de la variable
# Remove duplicate rows of the dataframe
raw_data %<>% distinct(country,.keep_all= TRUE) # quitamos los duplicados en base a los nombres de los países
data <- raw_data# renombramos los datos, ya que hemos realizado todas las transformaciones
# Remove duplicate rows of the dataframe
skim(data)
# Dibijamos los gg plot para saber la forma de la distribución de los datos, sobre todo si son o no liemales
par(mfrow = c(3, 2))
ggplot(data = data, mapping = aes(x = overall, y = interest)) +
geom_point() +
geom_smooth()
ggplot(data = data, mapping = aes(x = overall, y = support)) +
geom_point() +
geom_smooth()
ggplot(data = data, mapping = aes(x = overall, y = income)) +
geom_point() +
geom_smooth()
ggplot(data = data, mapping = aes(x = overall, y = health)) +
geom_point() +
geom_smooth()
ggplot(data = data, mapping = aes(x = overall, y = edu)) +
geom_point() +
geom_smooth()
ggplot(data = data, mapping = aes(x = overall, y = hdi)) +
geom_point() +
geom_smooth()
# Fit a linear model
lm_mod <- lm(overall~ interest + support + income + health + edu + hdi, data = data)
width(flextable(tidy(lm_mod)), width = 2)
width(flextable(glance(lm_mod)), width = 2)
# Visualize the model
termplot(lm_mod, partial.resid = TRUE, se = TRUE)
# Degres of the polynomial#
###########################
ggcorrplot(cor(data %>%
select_at(vars(-country,-evidence,-explain)),
use = "complete.obs"),
hc.order = TRUE,
type = "lower",  lab = TRUE)
chart.Correlation(data %>%  #las lineas rectas rojas, indican que no hay correlacion
select_at(vars(-country,-evidence,-explain)),
histogram=TRUE, pch=19)
dfinterest<-smooth.spline(x = data$interest,  y = data$overall, cv=TRUE)
dfsupport<-smooth.spline(data$support, data$overall, cv=TRUE)
dfincome<-smooth.spline(data$income, data$overall, cv=TRUE)
dfhealth<-smooth.spline(data$health, data$overall, cv=TRUE)
dfedu<-smooth.spline(data$edu, data$overall, cv=TRUE)
dfhdi<-smooth.spline(data$hdi, data$overall, cv=TRUE)
dfinterest$df
dfsupport$df
dfincome$df
dfhealth$df
dfedu$df
dfhdi$df
gam<- gam(overall ~ s(interest, 4.750171) + s(support, 2.001243) + s(income, 4.244952) + s(health, 2.002844) + s(edu, 2.002385) + s(hdi, 8.603228), data = data)
summary(gam)
par(mfrow = c(2, 3))
plot(gam, se = TRUE, col = 'dodgerblue', lwd = 2)
library(visreg)
par(mfrow=c(2,3))
visreg(gam)
gam.check(gam)
gam_2<- gam(overall ~ s(interest, 4.750171) + s(support, 2.001243) + s(income, 4.244952) + (health) + s(edu) + s(hdi, 8.603228), data = data)
summary(gam_2)
gam_2<- gam(overall ~ s(interest, 4.750171) + s(support, 2.001243) + s(income, 4.244952) + s(health) + s(edu) + s(hdi, 8.603228), data = data)
summary(gam_2)
gam_2<- gam(overall ~ s(interest, 4.750171) + s(support, 2.001243) + s(income, 4.244952) + (health) + (edu) + s(hdi, 8.603228), data = data)
summary(gam_2)
gam_2<- gam(overall ~ s(interest, 4.750171) + s(support, 2.001243) + s(income, 4.244952) + s(health) + s(edu) + s(hdi, 8.603228), data = data)
summary(gam_2)
library(visreg)
par(mfrow=c(2,3))
visreg(gam_2)
library(visreg)
par(mfrow=c(2,3))
visreg(gam)
gam_2<- gam(overall ~ s(interest, 4.750171) + s(support, 2.001243) + s(income, 4.244952)  + s(hdi, 8.603228), data = data)
summary(gam_2)
gam_2<- gam(overall ~ s(interest, 4.750171) + s(support, 2.001243) + s(income, 4.244952) + (health) + (edu) + s(hdi, 8.603228), data = data)
summary(gam_2)
library(tidyverse)
library(broom) # modelos en df
library(flextable) # Tablas formateadas
library(mgcv) # estimar gam
library(reshape2) # melt
library(readr)
library(dplyr)
library(skimr)
library(here) # Comentar
library(janitor) # Clean names
library(magrittr) # Pipe operators
library(corrplot) # Correlations
library(ggcorrplot)  # Correlations
library(PerformanceAnalytics) # Correlations
library(leaps) # Model selection
library(glmnet)
library(gam)
library(fBasics)
library(nortest)
library(MASS)
library(imputeTS)
library(gam)
raw_data <- read_csv("pisasci2006.csv")
str(raw_data) # visualizamos el tipo de variables de la base de datos, el número de observaciones y de variables
raw_data %<>% clean_names() # %<>% es un doble pipe, mete row_Data en clean_nnba y el resultado lo guarda en rowdata
# raw_data <- clean_nnba(raw_data)
# raw_data <- raw_data %>% clean_nnba()
# lo que hace es que nos limpia los nombre, todas en minusculas quitar los puntos
colnames(raw_data)
dim(raw_data)
skim(raw_data)
raw_data <- na_mean(raw_data) # sustituimos los NA por la media de la variable
# Remove duplicate rows of the dataframe
raw_data %<>% distinct(country,.keep_all= TRUE) # quitamos los duplicados en base a los nombres de los países
data <- raw_data# renombramos los datos, ya que hemos realizado todas las transformaciones
# Remove duplicate rows of the dataframe
skim(data)
# Dibijamos los gg plot para saber la forma de la distribución de los datos, sobre todo si son o no liemales
par(mfrow = c(3, 2))
ggplot(data = data, mapping = aes(x = overall, y = interest)) +
geom_point() +
geom_smooth()
ggplot(data = data, mapping = aes(x = overall, y = support)) +
geom_point() +
geom_smooth()
ggplot(data = data, mapping = aes(x = overall, y = income)) +
geom_point() +
geom_smooth()
ggplot(data = data, mapping = aes(x = overall, y = health)) +
geom_point() +
geom_smooth()
ggplot(data = data, mapping = aes(x = overall, y = edu)) +
geom_point() +
geom_smooth()
ggplot(data = data, mapping = aes(x = overall, y = hdi)) +
geom_point() +
geom_smooth()
# Fit a linear model
lm_mod <- lm(overall~ interest + support + income + health + edu + hdi, data = data)
width(flextable(tidy(lm_mod)), width = 2)
width(flextable(glance(lm_mod)), width = 2)
# Visualize the model
termplot(lm_mod, partial.resid = TRUE, se = TRUE)
# Degres of the polynomial#
###########################
ggcorrplot(cor(data %>%
select_at(vars(-country,-evidence,-explain)),
use = "complete.obs"),
hc.order = TRUE,
type = "lower",  lab = TRUE)
chart.Correlation(data %>%  #las lineas rectas rojas, indican que no hay correlacion
select_at(vars(-country,-evidence,-explain)),
histogram=TRUE, pch=19)
dfinterest<-smooth.spline(x = data$interest,  y = data$overall, cv=TRUE)
dfsupport<-smooth.spline(data$support, data$overall, cv=TRUE)
dfincome<-smooth.spline(data$income, data$overall, cv=TRUE)
dfhealth<-smooth.spline(data$health, data$overall, cv=TRUE)
dfedu<-smooth.spline(data$edu, data$overall, cv=TRUE)
dfhdi<-smooth.spline(data$hdi, data$overall, cv=TRUE)
dfinterest$df
dfsupport$df
dfincome$df
dfhealth$df
dfedu$df
dfhdi$df
gam<- gam(overall ~ s(interest, 4.750171) + s(support, 2.001243) + s(income, 4.244952) + s(health, 2.002844) + s(edu, 2.002385) + s(hdi, 8.603228), data = data)
summary(gam)
library(visreg)
par(mfrow=c(2,3))
visreg(gam)
gam_2<- gam(overall ~ s(interest, 4.750171) + s(support, 2.001243) + s(income, 4.244952) + s(health) + s(edu) + s(hdi, 8.603228), data = data)
summary(gam_2)
library(visreg)
par(mfrow=c(2,3))
visreg(gam_2)
gam_2<- gam(overall ~ s(interest, 4.750171) + s(support, 2.001243) + s(income, 4.244952) + s(hdi, 8.603228), data = data)
summary(gam_2)
gam_2<- gam(overall ~ s(interest, 4.750171) + s(support, 2.001243) + s(income, 4.244952) + (health) + (edu) + s(hdi, 8.603228), data = data)
summary(gam_2)
library(visreg)
par(mfrow=c(2,3))
visreg(gam_2)
gam_2<- gam(overall ~ s(interest, 4.750171) + s(support, 2.001243) + s(income, 4.244952)  + s(hdi, 8.603228), data = data)
summary(gam_2)
library(visreg)
par(mfrow=c(2,3))
visreg(gam_2)
gam_2<- gam(overall ~ s(interest, 4.750171) + s(support, 2.001243) + s(income, 4.244952) + (health) + (edu) + s(hdi, 8.603228), data = data)
summary(gam_2)
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)
# Dibijamos los gg plot para saber la forma de la distribución de los datos, sobre todo si son o no liemales
par(mfrow = c(3, 2))
ggplot(data = data, mapping = aes(x = overall, y = interest)) +
geom_point() +
geom_smooth()
ggplot(data = data, mapping = aes(x = overall, y = support)) +
geom_point() +
geom_smooth()
ggplot(data = data, mapping = aes(x = overall, y = income)) +
geom_point() +
geom_smooth()
ggplot(data = data, mapping = aes(x = overall, y = health)) +
geom_point() +
geom_smooth()
ggplot(data = data, mapping = aes(x = overall, y = edu)) +
geom_point() +
geom_smooth()
ggplot(data = data, mapping = aes(x = overall, y = hdi)) +
geom_point() +
geom_smooth()
# Fit a linear model
lm_mod <- lm(overall~ interest + support + income + health + edu + hdi, data = data)
width(flextable(tidy(lm_mod)), width = 2)
width(flextable(glance(lm_mod)), width = 2)
# Visualize the model
termplot(lm_mod, partial.resid = TRUE, se = TRUE)
# Dibijamos los gg plot para saber la forma de la distribución de los datos, sobre todo si son o no liemales
par(mfrow=c(2,3))
ggplot(data = data, mapping = aes(x = overall, y = interest)) +
geom_point() +
geom_smooth()
ggplot(data = data, mapping = aes(x = overall, y = support)) +
geom_point() +
geom_smooth()
ggplot(data = data, mapping = aes(x = overall, y = income)) +
geom_point() +
geom_smooth()
ggplot(data = data, mapping = aes(x = overall, y = health)) +
geom_point() +
geom_smooth()
ggplot(data = data, mapping = aes(x = overall, y = edu)) +
geom_point() +
geom_smooth()
ggplot(data = data, mapping = aes(x = overall, y = hdi)) +
geom_point() +
geom_smooth()
# Fit a linear model
par(mfrow=c(2,3))
lm_mod <- lm(overall~ interest + support + income + health + edu + hdi, data = data)
width(flextable(tidy(lm_mod)), width = 2)
width(flextable(glance(lm_mod)), width = 2)
# Visualize the model
termplot(lm_mod, partial.resid = TRUE, se = TRUE)
# Degres of the polynomial#
###########################
ggcorrplot(cor(data %>%
select_at(vars(-country,-evidence,-explain)),
use = "complete.obs"),
hc.order = TRUE,
type = "lower",  lab = TRUE)
chart.Correlation(data %>%  #las lineas rectas rojas, indican que no hay correlacion
select_at(vars(-country,-evidence,-explain)),
histogram=TRUE, pch=19)
